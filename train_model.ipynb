{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"name":"train_model.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3b8c5e19"},"source":["import numpy as np\n","import cv2\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D\n","from keras.optimizers import *\n","from keras.layers import MaxPooling2D\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n","from keras.models import Model, Sequential\n","# from keras.optimizers import Adam"],"id":"3b8c5e19","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gTEo1FJxNzFP"},"source":[""],"id":"gTEo1FJxNzFP","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0c6dfa60"},"source":[""],"id":"0c6dfa60","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyL6abySwjPZ","outputId":"96258802-33b4-4be3-ca7c-2d32c24a3827"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"JyL6abySwjPZ","execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWBjwIUBO57K","outputId":"7cf98f35-9d15-4359-948e-a23ce6276fb5"},"source":["cd drive/MyDrive/projects/emoji_creator/"],"id":"pWBjwIUBO57K","execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/projects/emoji_creator\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vOpHn5frOspC"},"source":["train_dir = 'data/train/'\n","val_dir = 'data/test/'"],"id":"vOpHn5frOspC","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ac9f5a1c","outputId":"594e103f-e8d7-4c77-c9b4-119b92c5a933"},"source":["train_datagen = ImageDataGenerator(rescale=1./255)\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(200,200),\n","        batch_size=64,\n","        color_mode=\"grayscale\",\n","        class_mode='categorical')\n","\n","validation_generator = val_datagen.flow_from_directory(\n","        val_dir,\n","        target_size=(200,200),\n","        batch_size=64,\n","        color_mode=\"grayscale\",\n","        class_mode='categorical')"],"id":"ac9f5a1c","execution_count":null,"outputs":[{"output_type":"stream","text":["Found 28709 images belonging to 7 classes.\n","Found 7178 images belonging to 7 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6g8OclU8RVWC"},"source":["emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}"],"id":"6g8OclU8RVWC","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c40f8539","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c31fa6c-0dc7-4010-a081-4dab52b36516"},"source":["# number of possible label values\n","nb_classes = 7\n","\n","# Initialising the CNN\n","model = Sequential()\n","\n","# 1 - Convolution\n","model.add(Conv2D(64,(3,3), padding='same', input_shape=(200, 200,1)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","# 2nd Convolution layer\n","model.add(Conv2D(128,(5,5), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","# 3rd Convolution layer\n","model.add(Conv2D(512,(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","# 4th Convolution layer\n","model.add(Conv2D(512,(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","# Flattening\n","model.add(Flatten())\n","\n","# Fully connected layer 1st layer\n","model.add(Dense(256))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.25))\n","\n","# Fully connected layer 2nd layer\n","model.add(Dense(512))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(nb_classes, activation='softmax'))\n","\n","print(model.summary())\n","\n","opt = Adam(lr=0.0001)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"],"id":"c40f8539","execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 48, 48, 64)        640       \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 48, 48, 64)        256       \n","_________________________________________________________________\n","activation (Activation)      (None, 48, 48, 64)        0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 24, 24, 128)       204928    \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 24, 24, 128)       512       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 24, 24, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 12, 12, 512)       590336    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 12, 12, 512)       2048      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 12, 12, 512)       0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 6, 6, 512)         2048      \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 4608)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               1179904   \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 256)               0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               131584    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 512)               2048      \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 4,478,727\n","Trainable params: 4,474,759\n","Non-trainable params: 3,968\n","_________________________________________________________________\n","None\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"b4719e2b"},"source":[""],"id":"b4719e2b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"50dccc7a","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ef8187f-46f6-433f-dff8-28374fd44358"},"source":["model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n","model_info = model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=28709 // 64,\n","        epochs=50,\n","        validation_data=validation_generator,\n","        validation_steps=7178 // 64)"],"id":"50dccc7a","execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/50\n","133/448 [=======>......................] - ETA: 1:23:07 - loss: 2.1408 - accuracy: 0.1959"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b57ddd91"},"source":["model.save_weights('emotion_model.h5')"],"id":"b57ddd91","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"84f124d2"},"source":["# start the webcam feed\n","cap = cv2.VideoCapture(0)\n","while True:\n","    # Find haar cascade to draw bounding box around face\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    bounding_box = cv2.CascadeClassifier('drive/MyDrive/projects/emoji_creator/data/haarcascade_frontalface_default.xml')\n","    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2gray_frame)\n","    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)\n","\n","    for (x, y, w, h) in num_faces:\n","        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n","        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n","        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)\n","        emotion_prediction = emotion_model.predict(cropped_img)\n","        maxindex = int(np.argmax(emotion_prediction))\n","        cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","\n","    cv2.imshow('Video', cv2.resize(frame,(1200,860),interpolation = cv2.INTER_CUBIC))\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"],"id":"84f124d2","execution_count":null,"outputs":[]}]}